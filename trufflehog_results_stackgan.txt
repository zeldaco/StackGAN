~~~~~~~~~~~~~~~~~~~~~
[92mReason: High Entropy[0m
[92mDate: 2016-12-21 19:34:49[0m
[92mHash: aeb60b07f15fbd4fc766457e044dfc5be11cd688[0m
[92mFilepath: README.md[0m
[92mBranch: origin/master[0m
[92mCommit: first commit
[0m
@@ -0,0 +1,91 @@
+# StackGAN
+Code for reproducing main results in the paper [StackGAN: Text to Photo-realistic Image Synthesis
+with Stacked Generative Adversarial Networks](https://arxiv.org/pdf/1612.03242v1.pdf) by Han Zhang, Tao Xu, Hongsheng Li, Shaoting Zhang, Xiaolei Huang, Xiaogang Wang, Dimitris Metaxas.
+
+<img src="examples/framework.png" width="700px" height="370px"/>
+
+
+### Dependencies
+[TensorFlow](https://www.tensorflow.org/get_started/os_setup)
+
+[Optional] [Torch](http://torch.ch/docs/getting-started.html#_) is needed, if use the pre-trained char-CNN-RNN text encoder.
+
+[Optional] [skip-thought](https://github.com/ryankiros/skip-thoughts) is needed, if use the skip-thought text encoder.
+
+In addition, please add the project folder to PYTHONPATH and `pip install` the following packages:
+- `prettytensor`
+- `progressbar`
+- `python-dateutil`
+- `easydict`
+- `pandas`
+- `torchfile`
+
+
+
+**Data**
+
+1. Download our preprocessed char-CNN-RNN text embeddings for [birds](https://drive.google.com/open?id=0B3y_msrWZaXLT1BZdVdycDY5TEE) and [flowers](https://drive.google.com/open?id=0B3y_msrWZaXLaUc0UXpmcnhaVmM) and save them to `Data/`.
+  - [Optional] Follow the instructions [reedscot/icml2016](https://github.com/reedscot/icml2016) to download the pretrained char-CNN-RNN text encoders and extract text embeddings.
+2. Download the [birds](http://www.vision.caltech.edu/visipedia/CUB-200-2011.html) and [flowers](http://www.robots.ox.ac.uk/~vgg/data/flowers/102/) image data. Extract them to `Data/birds/` and `Data/flowers/`, respectively.
+3. Preprocess images.
+  - For birds: `python misc/preprocess_birds.py`
+  - For flowers: `python misc/preprocess_flowers.py`
+
+
+
+**Training**
+- The steps to train a StackGAN model on the CUB dataset using our preprocessed data for birds.
+  - Step 1: train Stage-I GAN (e.g., for 600 epochs) `python stageI/run_exp.py --cfg stageI/cfg/birds.yml --gpu 0`
+  - Step 2: train Stage-II GAN (e.g., for another 600 epochs) `python stageII/run_exp.py --cfg stageII/cfg/birds.yml --gpu 1`
+- Change `birds.yml` to `flowers.yml` to train a StackGAN model on Oxford-102 dataset using our preprocessed data for flowers.
+- `*.yml` files are example configuration files for training/testing our models.
+- If you want to try your own datasets, [here](https://github.com/soumith/ganhacks) are some good tips about how to train GAN. Also, we encourage to try different hyper-parameters and architectures, especially for more complex datasets.
+
+
+
+**Pretrained Model**
+- [StackGAN for birds](https://drive.google.com/open?id=0B3y_msrWZaXLNUNKa3BaRjAyTzQ) trained from char-CNN-RNN text embeddings. Download and save it to `models/`.
+- [StackGAN for flowers](https://drive.google.com/open?id=0B3y_msrWZaXLX01FMC1JQW9vaFk) trained from char-CNN-RNN text embeddings. Download and save it to `models/`.
+- [StackGAN for birds](https://drive.google.com/open?id=0B3y_msrWZaXLZVNRNFg4d055Q1E) trained from skip-thought text embeddings. Download and save it to `models/` (Just used the same setting as the char-CNN-RNN. We assume better results can be achieved by playing with the hyper-parameters).
+
+
+
+**Run Demos**
+- Run `sh demo/flowers_demo.sh` to generate flower samples from sentences. The results will be saved to `Data/flowers/example_captions/`. (Need to [download](https://drive.google.com/file/d/0B0ywwgffWnLLZUt0UmQ1LU1oWlU/view) the char-CNN-RNN text encoder for flowers to `models/text_encoder/`. Note: this text encoder is provided by [reedscot/icml2016](https://github.com/reedscot/icml2016)).
+- Run `sh demo/birds_demo.sh` to generate bird samples from sentences. The results will be saved to `Data/birds/example_captions/`.(Need to [download](https://drive.google.[93mcom/file/d/0B0ywwgffWnLLU0F3UHA3NzFTNEE/view[0m) the char-CNN-RNN text encoder for birds to `models/text_encoder/`. Note: this text encoder is provided by [reedscot/icml2016](https://github.com/reedscot/icml2016)).
+- Run `python demo/birds_skip_thought_demo.py --cfg demo/cfg/birds-skip-thought-demo.yml --gpu 2` to generate bird samples from sentences. The results will be saved to `Data/birds/example_captions-skip-thought/`. (Need to [download](https://github.com/ryankiros/skip-thoughts) vocabulary for skip-thought vectors to `Data/skipthoughts/`).
+
+Examples for birds (char-CNN-RNN embeddings), more on [youtube](https://youtu.be/93yaf_kE0Fg):
+![](examples/bird1.jpg)
+![](examples/bird2.jpg)
+![](examples/bird4.jpg)
+![](examples/bird3.jpg)
+
+
+Examples for flowers (char-CNN-RNN embeddings), more on [youtube](https://youtu.be/SuRyL5vhCIM):
+![](examples/flower1.jpg)
+![](examples/flower2.jpg)
+![](examples/flower3.jpg)
+![](examples/flower4.jpg)
+
+Save your favorite pictures generated by our models since the randomness from noise z and conditioning augmentation makes them creative enough to generate objects with different poses and viewpoints from the same discription :smiley:
+
+
+
+### Citing StackGAN
+If you find StackGAN useful in your research, please consider citing:
+
+```
+@article{han2016stackgan,
+  title={StackGAN: Text to Photo-realistic Image Synthesis with Stacked Generative Adversarial Networks},
+  author={Han Zhang and Tao Xu and Hongsheng Li and Shaoting Zhang and Xiaolei Huang and Xiaogang Wang and Dimitris Metaxas},
+  journal={arXiv:1612.03242},
+  year={2016}
+}
+```
+
+
+**References**
+
+- Generative Adversarial Text-to-Image Synthesis [Paper](https://arxiv.org/abs/1605.05396) [Code](https://github.com/reedscot/icml2016)
+- Learning Deep Representations of Fine-grained Visual Descriptions [Paper](https://arxiv.org/abs/1605.05395) [Code](https://github.com/reedscot/cvpr2016)

~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~
[92mReason: High Entropy[0m
[92mDate: 2016-12-21 19:34:49[0m
[92mHash: aeb60b07f15fbd4fc766457e044dfc5be11cd688[0m
[92mFilepath: demo/get_embedding.lua[0m
[92mBranch: origin/master[0m
[92mCommit: first commit
[0m
@@ -0,0 +1,63 @@
+-- Modification from the codebase of scott's icml16
+-- please check https://github.com/reedscot/icml2016 for details
+
+require 'image'
+require 'nn'
+require 'nngraph'
+require 'cunn'
+require 'cutorch'
+require 'cudnn'
+require 'lfs'
+require 'torch'
+
+
+
+torch.setdefaulttensortype('torch.FloatTensor')
+
+local alphabet = "[93mabcdefghijklmnopqrstuvwxyz0123456789[0m-,;.!?:'\"/\\|_@#$%^&*~`+-=<>()[]{} "
+local dict = {}
+for i = 1,#alphabet do
+    dict[alphabet:sub(i,i)] = i
+end
+ivocab = {}
+for k,v in pairs(dict) do
+  ivocab[v] = k
+end
+
+opt = {
+  filenames = '',
+  doc_length = 201,
+  queries = 'cub_queries.txt',
+  net_txt = '',
+}
+
+for k,v in pairs(opt) do opt[k] = tonumber(os.getenv(k)) or os.getenv(k) or opt[k] end
+print(opt)
+
+net_txt = torch.load(opt.net_txt)
+if net_txt.protos ~=nil then net_txt = net_txt.protos.enc_doc end
+
+
+net_txt:evaluate()
+
+-- Extract all text features.
+local fea_txt = {}
+-- Decode text for sanity check.
+local raw_txt = {}
+local raw_img = {}
+for query_str in io.lines(opt.queries) do
+  local txt = torch.zeros(1,opt.doc_length,#alphabet)
+  for t = 1,opt.doc_length do
+    local ch = query_str:sub(t,t)
+    local ix = dict[ch]
+    if ix ~= 0 and ix ~= nil then
+      txt[{1,t,ix}] = 1
+    end
+  end
+  raw_txt[#raw_txt+1] = query_str
+  txt = txt:cuda()
+
+  fea_txt[#fea_txt+1] = net_txt:forward(txt):clone()
+end
+
+torch.save(opt.filenames, {raw_txt=raw_txt, fea_txt=fea_txt})

~~~~~~~~~~~~~~~~~~~~~
~~~~~~~~~~~~~~~~~~~~~
[92mReason: High Entropy[0m
[92mDate: 2016-12-21 19:34:49[0m
[92mHash: aeb60b07f15fbd4fc766457e044dfc5be11cd688[0m
[92mFilepath: models/README.md[0m
[92mBranch: origin/master[0m
[92mCommit: first commit
[0m
@@ -0,0 +1,9 @@
+**Pretrained StackGAN Models**
+- [StackGAN for birds]() trained from char-CNN-RNN text embeddings. Download and save it to `models/`.
+- [StackGAN for flowers](https://drive.google.com/open?id=0B3y_msrWZaXLX01FMC1JQW9vaFk) trained from char-CNN-RNN text embeddings. Download and save it to `models/`.
+- [StackGAN for birds](https://drive.google.com/open?id=0B3y_msrWZaXLZVNRNFg4d055Q1E) trained from skip-thought text embeddings. Download and save it to `models/` (Just use the same setting as the char-CNN-RNN, we assume better results can be achieved by playing with the hyper-parameters).
+
+
+**char-CNN-RNN text encoders**
+- [Download](https://drive.google.com/file/d/0B0ywwgffWnLLZUt0UmQ1LU1oWlU/view) the char-CNN-RNN text encoder for flowers to `models/text_encoder/`.
+- [Download](https://drive.google.[93mcom/file/d/0B0ywwgffWnLLU0F3UHA3NzFTNEE/view[0m) the char-CNN-RNN text encoder for birds to `models/text_encoder/`.

~~~~~~~~~~~~~~~~~~~~~
